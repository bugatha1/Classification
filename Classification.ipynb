{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classification.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMMvHaGYPPhov4h+nY+nLLD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bugatha1/Classification/blob/main/Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression\n",
        "It is similar to linear regression.                                             \n",
        "Problem : Need to predict the probability(chances) of our customers to accept   our offer based on their age.                                                   \n",
        "Solution : logistic regression model.                                           \n",
        "Explanation: Based on the training data we come to know the age of the          customers who took the offer. Suppose the customers whose age is more than 50   are likely to accept our offer and the customers who age is less than 50 are    not accept our offer.                                                           "
      ],
      "metadata": {
        "id": "aBCkx3Xk4JJU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Logistic regression model on training dataset\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier = LogisticRegression(random_state=0)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# predict \n",
        "classifier.predict([[30, 87000]])"
      ],
      "metadata": {
        "id": "vz9NJOI87NzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Confusion Metrix\n",
        "\n",
        "shows correct predictions and incorrect predictions"
      ],
      "metadata": {
        "id": "49NhhdzjKLiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_metrix, accuracy_score\n",
        "cm = confusion_metrix(y_test, y_pred)\n",
        "print(cm)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "metadata": {
        "id": "uT3foVjKKqfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# KNN (K- Nearest Neighbors)\n",
        "step1 : Choose the number k of neighbors                                        \n",
        "step2: Take the K nearest neighbors of the new data point, according to the     Euclidean distance (sqrt(pow2(x2-x1)+pow2(y2-y1))                               \n",
        "step3: Among these K neighbors, count the number of data points in each category\n",
        "step4: Assign the new data point to the category where you counted the most     neighbors"
      ],
      "metadata": {
        "id": "k4Pts2XcO1wt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# K-NN model on the training set\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=5, metric='minkowski', p=2)  # p= 1 means manhatten_distance and 2 means euclidean distance\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "gfB3YHsucdBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM (Support Vector Machine)\n",
        "SVM (linear) will be used if data is separated linearly.                        \n",
        "Finding best line or best decision boundary which will separte our space (dataset) into classes (categories)"
      ],
      "metadata": {
        "id": "hDGFwRH-u_PY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SVM model on the training set\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel='linear', random_state=0)\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "vAFiXy4rwu6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Types of Kernel  functions\n",
        "Gaussian RBF Kernel                                                             \n",
        "sigmoid kernel                                                                  \n",
        "polynomial kernel"
      ],
      "metadata": {
        "id": "qCMuzureNvSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Non linear SVR"
      ],
      "metadata": {
        "id": "tE2FTXKjPD-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# kernel svm model on the training set\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "classifier = SVC(kernel = 'rbf', random_state=0)  # rbf = regional basis function\n",
        "classifier.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "kAfucWJobSBW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}